{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# 🐛 Google Colab上でのYOLOv8昆虫検出トレーニング\n\n**プロジェクト**: 昆虫検出トレーニングプロジェクト  \n**目的**: Roboflowデータセットを使用してカブトムシ検出のためのカスタムYOLOv8モデルを訓練  \n**環境**: GPU加速付きGoogle Colaboratory  \n\n---\n\n## 📋 概要\n\nこのノートブックはYOLOv8昆虫検出モデルのためのインタラクティブトレーニングパイプラインを提供します。含まれる機能:\n\n- ✅ 自動化された環境セットアップ\n- ✅ GPU設定と検証\n- ✅ データセットの準備と検証\n- ✅ インタラクティブなモデルトレーニング\n- ✅ リアルタイム進捗監視\n- ✅ モデル評価とエクスポート\n- ✅ 結果の可視化\n\n---\n\n## ⚡ クイックスタート\n\n1. **GPUを有効化**: ランタイム → ランタイムタイプの変更 → GPUを選択\n2. **すべてのセルを実行**: ランタイム → すべてのセルを実行\n3. **データセットをアップロード**: プロンプトに従ってデータセットをアップロード\n4. **トレーニングを監視**: リアルタイムトレーニング進捗を監視\n5. **結果をダウンロード**: 訓練済みモデルをGoogle Driveに保存\n\n---",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": "## 🛠️ ステップ1: 環境セットアップとライブラリのインストール",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-libraries"
   },
   "outputs": [],
   "source": "# 必要なライブラリのインストール\nprint(\"🔧 必要なライブラリをインストール中...\")\n\n!pip install ultralytics roboflow supervision\n!pip install --upgrade torch torchvision\n\nprint(\"✅ インストールが完了しました！\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": "# 必要なライブラリのインポート\nimport os\nimport sys\nimport time\nimport shutil\nimport zipfile\nfrom pathlib import Path\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# 深層学習ライブラリ\nimport torch\nimport torchvision\nfrom ultralytics import YOLO\n\n# データ操作と可視化\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Image, display, HTML, clear_output\nimport cv2\n\n# Google Colab専用\nfrom google.colab import files, drive\nimport yaml\n\nprint(\"📚 ライブラリのインポートが完了しました！\")\nprint(f\"🐍 Pythonバージョン: {sys.version}\")\nprint(f\"🔥 PyTorchバージョン: {torch.__version__}\")\nprint(f\"👁️ OpenCVバージョン: {cv2.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu-header"
   },
   "source": "## 🚀 ステップ2: GPU設定とシステム検証",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": "# GPU可用性と設定の確認\ndef check_gpu_setup():\n    \"\"\"GPU設定をチェックし、利用可能な場合はデバイスを設定する\"\"\"\n    print(\"🔍 GPU設定を確認中...\")\n    print(\"=\"*50)\n    \n    # CUDA可用性の確認\n    cuda_available = torch.cuda.is_available()\n    print(f\"CUDA利用可能: {cuda_available}\")\n    \n    if cuda_available:\n        device_count = torch.cuda.device_count()\n        print(f\"GPU数: {device_count}\")\n        \n        for i in range(device_count):\n            gpu_name = torch.cuda.get_device_name(i)\n            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n        \n        # デバイスの設定\n        device = torch.device('cuda:0')\n        print(f\"\\n✅ 使用デバイス: {device}\")\n        \n        # 簡単な演算でGPUをテスト\n        test_tensor = torch.rand(1000, 1000).to(device)\n        result = torch.mm(test_tensor, test_tensor.t())\n        print(\"✅ GPUテスト操作が成功しました！\")\n        \n    else:\n        print(\"⚠️ GPUが利用できません。トレーニングはCPUを使用します（低速）。\")\n        device = torch.device('cpu')\n    \n    print(\"=\"*50)\n    return device\n\n# GPU確認の実行\ntraining_device = check_gpu_setup()"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "system-info"
   },
   "outputs": [],
   "source": "# システム情報の表示\ndef display_system_info():\n    \"\"\"システム情報を表示する\"\"\"\n    print(\"💻 システム情報\")\n    print(\"=\"*40)\n    \n    # CPU情報\n    print(f\"CPUコア数: {os.cpu_count()}\")\n    \n    # メモリ情報（概算）\n    import psutil\n    memory = psutil.virtual_memory()\n    print(f\"RAM: {memory.total / 1e9:.1f} GB （利用可能: {memory.available / 1e9:.1f} GB）\")\n    \n    # ディスク容量\n    disk = psutil.disk_usage('/')\n    print(f\"ディスク: {disk.total / 1e9:.1f} GB （空き: {disk.free / 1e9:.1f} GB）\")\n    \n    print(\"\\n🔧 ソフトウェアバージョン\")\n    print(\"=\"*40)\n    print(f\"Python: {sys.version.split()[0]}\")\n    print(f\"PyTorch: {torch.__version__}\")\n    print(f\"Torchvision: {torchvision.__version__}\")\n    print(f\"OpenCV: {cv2.__version__}\")\n    print(f\"NumPy: {np.__version__}\")\n    \ndisplay_system_info()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive-header"
   },
   "source": "## 📁 ステップ3: Google Drive連携とデータセットセットアップ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": "# Google Driveをマウント\nprint(\"📁 Google Driveをマウント中...\")\ndrive.mount('/content/drive')\n\n# Google Drive内にプロジェクトディレクトリを作成\nproject_dir = Path('/content/drive/MyDrive/insect_detection_training')\nproject_dir.mkdir(exist_ok=True)\n\n# サブディレクトリを作成\n(project_dir / 'datasets').mkdir(exist_ok=True)\n(project_dir / 'models').mkdir(exist_ok=True)\n(project_dir / 'results').mkdir(exist_ok=True)\n(project_dir / 'logs').mkdir(exist_ok=True)\n\nprint(f\"✅ プロジェクトディレクトリを作成しました: {project_dir}\")\nprint(f\"📂 作業ディレクトリ: {os.getcwd()}\")\n\n# 作業ディレクトリを設定\nos.chdir('/content')\nprint(f\"📁 作業ディレクトリを変更しました: {os.getcwd()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-header"
   },
   "source": "## 📊 ステップ4: データセットの準備とアップロード\n\n### オプションA: ローカルコンピューターからアップロード",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "upload-dataset"
   },
   "outputs": [],
   "source": "# オプションA: ローカルコンピューターからデータセットをアップロード\ndef upload_dataset_local():\n    \"\"\"ローカルコンピューターからデータセットをアップロードする\"\"\"\n    print(\"📤 データセットのZIPファイルをアップロードしてください\")\n    print(\"ZIP内の期待される構造:\")\n    print(\"\"\"\n    dataset.zip\n    ├── train/\n    │   ├── images/\n    │   └── labels/\n    ├── valid/\n    │   ├── images/\n    │   └── labels/\n    ├── test/\n    │   ├── images/\n    │   └── labels/\n    └── data.yaml\n    \"\"\")\n    \n    uploaded = files.upload()\n    \n    # アップロードされたファイルを展開\n    for filename in uploaded.keys():\n        if filename.endswith('.zip'):\n            print(f\"📦 {filename}を展開中...\")\n            with zipfile.ZipFile(filename, 'r') as zip_ref:\n                zip_ref.extractall('datasets')\n            print(\"✅ データセットの展開が完了しました！\")\n            break\n    else:\n        print(\"❌ ZIPファイルが見つかりません。データセットを含むZIPファイルをアップロードしてください。\")\n        return False\n    \n    return True\n\n# データセットをアップロード\nupload_success = upload_dataset_local()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roboflow-header"
   },
   "source": "### オプションB: Roboflowからダウンロード（推奨）",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "roboflow-download"
   },
   "outputs": [],
   "source": "# オプションB: Roboflowからダウンロード\ndef download_roboflow_dataset():\n    \"\"\"Roboflowからカブトムシデータセットをダウンロードする\"\"\"\n    print(\"🤖 Roboflowからカブトムシデータセットをダウンロード中...\")\n    \n    try:\n        from roboflow import Roboflow\n        \n        # Roboflowの初期化（APIキーの設定が必要な場合があります）\n        # APIキーの取得先: https://app.roboflow.com/settings/api\n        print(\"🔑 Roboflow APIキーを入力してください（スキップする場合はEnterを押してください）:\")\n        api_key = input(\"APIキー: \").strip()\n        \n        if api_key:\n            rf = Roboflow(api_key=api_key)\n            project = rf.workspace(\"z-algae-bilby\").project(\"beetle\")\n            dataset = project.version(1).download(\"yolov8\", location=\"datasets\")\n            print(\"✅ Roboflowからデータセットをダウンロードしました！\")\n            return True\n        else:\n            print(\"⚠️ APIキーが提供されませんでした。以下から手動でダウンロードできます:\")\n            print(\"https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1\")\n            return False\n            \n    except Exception as e:\n        print(f\"❌ Roboflowからのダウンロードエラー: {e}\")\n        print(\"💡 代替案: 手動でダウンロードしてオプションAでアップロードしてください\")\n        return False\n\n# Roboflowからダウンロード\ndownload_success = download_roboflow_dataset()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "manual-setup-header"
   },
   "source": "### オプションC: 手動データセットセットアップ（テスト用）",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "manual-dataset"
   },
   "outputs": [],
   "source": "# オプションC: テスト用サンプルデータセットの作成\ndef create_sample_dataset():\n    \"\"\"テスト用のサンプルデータセット構造を作成する\"\"\"\n    print(\"🧪 テスト用のサンプルデータセット構造を作成中...\")\n    \n    # ディレクトリ構造の作成\n    base_dir = Path('datasets')\n    for split in ['train', 'valid', 'test']:\n        (base_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n        (base_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n    \n    # サンプルdata.yamlの作成\n    data_yaml = {\n        'train': './train/images',\n        'val': './valid/images', \n        'test': './test/images',\n        'nc': 1,\n        'names': ['beetle'],\n        'roboflow': {\n            'workspace': 'z-algae-bilby',\n            'project': 'beetle',\n            'version': 1,\n            'license': 'CC BY 4.0',\n            'url': 'https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1'\n        }\n    }\n    \n    with open(base_dir / 'data.yaml', 'w') as f:\n        yaml.dump(data_yaml, f, default_flow_style=False)\n    \n    print(\"✅ サンプルデータセット構造を作成しました！\")\n    print(\"⚠️ 注意: これは構造のみです。実際の画像とラベルを追加する必要があります。\")\n    return True\n\n# サンプル構造を作成するには以下の行のコメントを外してください\n# create_sample_dataset()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validation-header"
   },
   "source": "## ✅ ステップ5: データセットの検証と解析",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate-dataset"
   },
   "outputs": [],
   "source": [
    "# Validate dataset structure and contents\n",
    "def validate_dataset(dataset_path='datasets'):\n",
    "    print(\"🔍 Validating dataset structure...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    dataset_dir = Path(dataset_path)\n",
    "    \n",
    "    # Check if data.yaml exists\n",
    "    data_yaml_path = dataset_dir / 'data.yaml'\n",
    "    if not data_yaml_path.exists():\n",
    "        print(\"❌ data.yaml not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Load and display data.yaml\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"📄 Dataset Configuration (data.yaml):\")\n",
    "    for key, value in data_config.items():\n",
    "        if key != 'roboflow':\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Check directory structure and count files\n",
    "    results = {}\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        images_dir = dataset_dir / split / 'images'\n",
    "        labels_dir = dataset_dir / split / 'labels'\n",
    "        \n",
    "        if images_dir.exists() and labels_dir.exists():\n",
    "            image_files = list(images_dir.glob('*.[jp][pn]g')) + list(images_dir.glob('*.jpeg'))\n",
    "            label_files = list(labels_dir.glob('*.txt'))\n",
    "            \n",
    "            results[split] = {\n",
    "                'images': len(image_files),\n",
    "                'labels': len(label_files)\n",
    "            }\n",
    "            \n",
    "            status = \"✅\" if len(image_files) == len(label_files) and len(image_files) > 0 else \"⚠️\"\n",
    "            print(f\"{status} {split.upper()}: {len(image_files)} images, {len(label_files)} labels\")\n",
    "        else:\n",
    "            print(f\"❌ {split.upper()}: Directory not found\")\n",
    "            results[split] = {'images': 0, 'labels': 0}\n",
    "    \n",
    "    # Calculate total\n",
    "    total_images = sum(split['images'] for split in results.values())\n",
    "    total_labels = sum(split['labels'] for split in results.values())\n",
    "    \n",
    "    print(f\"\\n📊 TOTAL: {total_images} images, {total_labels} labels\")\n",
    "    \n",
    "    if total_images > 0 and total_images == total_labels:\n",
    "        print(\"✅ Dataset validation successful!\")\n",
    "        return True, data_config, results\n",
    "    else:\n",
    "        print(\"❌ Dataset validation failed!\")\n",
    "        return False, None, None\n",
    "\n",
    "# Run validation\n",
    "validation_success, dataset_config, dataset_stats = validate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-dataset"
   },
   "outputs": [],
   "source": [
    "# Visualize dataset statistics\n",
    "def visualize_dataset_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"❌ No dataset statistics to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 Dataset Statistics Visualization\")\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Images per split\n",
    "    splits = list(stats.keys())\n",
    "    image_counts = [stats[split]['images'] for split in splits]\n",
    "    \n",
    "    bars1 = ax1.bar(splits, image_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    ax1.set_title('Images per Split', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Images')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars1, image_counts):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Split distribution pie chart\n",
    "    total = sum(image_counts)\n",
    "    percentages = [count/total*100 for count in image_counts]\n",
    "    \n",
    "    ax2.pie(percentages, labels=[f'{split}\\n({count} images)' for split, count in zip(splits, image_counts)], \n",
    "            autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    ax2.set_title('Dataset Split Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📈 Dataset Summary:\")\n",
    "    print(f\"Total Images: {total}\")\n",
    "    for split, count in zip(splits, image_counts):\n",
    "        percentage = count/total*100\n",
    "        print(f\"{split.upper()}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize if validation was successful\n",
    "if validation_success:\n",
    "    visualize_dataset_stats(dataset_stats)\n",
    "else:\n",
    "    print(\"⚠️ Cannot visualize dataset - validation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample-images"
   },
   "outputs": [],
   "source": [
    "# Display sample images from dataset\n",
    "def display_sample_images(dataset_path='datasets', num_samples=6):\n",
    "    if not validation_success:\n",
    "        print(\"⚠️ Cannot display samples - dataset validation failed\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🖼️ Displaying {num_samples} sample images from training set\")\n",
    "    \n",
    "    dataset_dir = Path(dataset_path)\n",
    "    train_images = list((dataset_dir / 'train' / 'images').glob('*.[jp][pn]g'))\n",
    "    \n",
    "    if len(train_images) == 0:\n",
    "        print(\"❌ No images found in training set\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    sample_images = np.random.choice(train_images, min(num_samples, len(train_images)), replace=False)\n",
    "    \n",
    "    # Create subplot\n",
    "    cols = 3\n",
    "    rows = (num_samples + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    \n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Load and display image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f\"Sample {i+1}: {img_path.name}\", fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(sample_images), rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "display_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-header"
   },
   "source": "## 🎯 ステップ6: トレーニング設定とモデル選択",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-config"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration class\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Model configuration\n",
    "        self.model_size = 'n'  # n, s, m, l, x (nano, small, medium, large, extra-large)\n",
    "        self.pretrained_model = f'yolov8{self.model_size}.pt'\n",
    "        \n",
    "        # Training parameters\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 16  # Adjust based on GPU memory\n",
    "        self.image_size = 640\n",
    "        self.device = 'auto'  # auto, cpu, 0, 1, etc.\n",
    "        \n",
    "        # Data configuration\n",
    "        self.data_yaml = 'datasets/data.yaml'\n",
    "        \n",
    "        # Output configuration\n",
    "        self.project_name = 'training_results'\n",
    "        self.experiment_name = 'beetle_detection_colab'\n",
    "        \n",
    "        # Advanced settings\n",
    "        self.patience = 50  # Early stopping patience\n",
    "        self.save_period = 10  # Save checkpoint every N epochs\n",
    "        self.workers = 2  # Number of dataloader workers\n",
    "        \n",
    "        # Optimization\n",
    "        self.optimizer = 'AdamW'  # SGD, Adam, AdamW\n",
    "        self.lr0 = 0.01  # Initial learning rate\n",
    "        self.weight_decay = 0.0005\n",
    "        \n",
    "    def display_config(self):\n",
    "        \"\"\"Display current configuration\"\"\"\n",
    "        print(\"🎯 Training Configuration\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Model: {self.pretrained_model}\")\n",
    "        print(f\"Epochs: {self.epochs}\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(f\"Image Size: {self.image_size}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Dataset: {self.data_yaml}\")\n",
    "        print(f\"Project: {self.project_name}/{self.experiment_name}\")\n",
    "        print(f\"Optimizer: {self.optimizer}\")\n",
    "        print(f\"Learning Rate: {self.lr0}\")\n",
    "        print(f\"Weight Decay: {self.weight_decay}\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "# Create configuration\n",
    "config = TrainingConfig()\n",
    "config.display_config()\n",
    "\n",
    "# GPU memory optimization\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"\\n🎮 GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Adjust batch size based on GPU memory\n",
    "    if gpu_memory < 8:\n",
    "        config.batch_size = 8\n",
    "        print(\"⚡ Reduced batch size to 8 for GPU memory optimization\")\n",
    "    elif gpu_memory >= 16:\n",
    "        config.batch_size = 32\n",
    "        print(\"🚀 Increased batch size to 32 for better GPU utilization\")\n",
    "    \n",
    "print(f\"\\n📊 Final Batch Size: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-training-header"
   },
   "source": "## 🚀 ステップ7: モデルトレーニング実行",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "def load_pretrained_model(model_name):\n",
    "    print(f\"📥 Loading pre-trained model: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_name)\n",
    "        print(f\"✅ Model loaded successfully!\")\n",
    "        \n",
    "        # Display model info\n",
    "        print(f\"\\n📋 Model Information:\")\n",
    "        print(f\"Model file: {model_name}\")\n",
    "        print(f\"Task: {model.task}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the model\n",
    "model = load_pretrained_model(config.pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-execution"
   },
   "outputs": [],
   "source": [
    "# Execute model training\n",
    "def train_model(model, config):\n",
    "    if model is None:\n",
    "        print(\"❌ Cannot start training - model not loaded\")\n",
    "        return None\n",
    "    \n",
    "    if not validation_success:\n",
    "        print(\"❌ Cannot start training - dataset validation failed\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🚀 Starting model training...\")\n",
    "    print(\"⏱️ This may take a while depending on your configuration\")\n",
    "    print(\"📊 Training progress will be displayed below\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Start training\n",
    "        results = model.train(\n",
    "            data=config.data_yaml,\n",
    "            epochs=config.epochs,\n",
    "            batch=config.batch_size,\n",
    "            imgsz=config.image_size,\n",
    "            device=config.device,\n",
    "            project=config.project_name,\n",
    "            name=config.experiment_name,\n",
    "            save=True,\n",
    "            save_period=config.save_period,\n",
    "            patience=config.patience,\n",
    "            workers=config.workers,\n",
    "            optimizer=config.optimizer,\n",
    "            lr0=config.lr0,\n",
    "            weight_decay=config.weight_decay,\n",
    "            val=True,\n",
    "            plots=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Calculate training time\n",
    "        training_time = time.time() - start_time\n",
    "        hours = int(training_time // 3600)\n",
    "        minutes = int((training_time % 3600) // 60)\n",
    "        seconds = int(training_time % 60)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"✅ Training completed successfully!\")\n",
    "        print(f\"⏱️ Total training time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "        print(f\"📁 Results saved to: {config.project_name}/{config.experiment_name}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Start training (this will take a while!)\n",
    "print(\"⚠️ Warning: Training will start in 5 seconds...\")\n",
    "time.sleep(5)\n",
    "\n",
    "training_results = train_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": "## 📊 ステップ8: トレーニング結果の解析と可視化",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display-results"
   },
   "outputs": [],
   "source": [
    "# Display training results\n",
    "def display_training_results(results, config):\n",
    "    if results is None:\n",
    "        print(\"❌ No training results to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 Training Results Summary\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Results directory\n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    \n",
    "    # Display key metrics if available\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        metrics = results.results_dict\n",
    "        print(\"🎯 Final Metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    # Check for results plots\n",
    "    plots_to_show = [\n",
    "        ('results.png', '📈 Training/Validation Curves'),\n",
    "        ('confusion_matrix.png', '🎯 Confusion Matrix'),\n",
    "        ('labels.jpg', '📊 Label Distribution'),\n",
    "        ('val_batch0_pred.jpg', '🔍 Validation Predictions')\n",
    "    ]\n",
    "    \n",
    "    for plot_file, title in plots_to_show:\n",
    "        plot_path = results_dir / plot_file\n",
    "        if plot_path.exists():\n",
    "            print(f\"\\n{title}\")\n",
    "            display(Image(str(plot_path)))\n",
    "        else:\n",
    "            print(f\"⚠️ {title} not found: {plot_path}\")\n",
    "\n",
    "# Display results\n",
    "if training_results:\n",
    "    display_training_results(training_results, config)\n",
    "else:\n",
    "    print(\"⚠️ No training results available to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-validation"
   },
   "outputs": [],
   "source": [
    "# Load best model and run validation\n",
    "def validate_trained_model(config):\n",
    "    print(\"🧪 Loading best model for validation...\")\n",
    "    \n",
    "    # Path to best model\n",
    "    best_model_path = Path(config.project_name) / config.experiment_name / 'weights' / 'best.pt'\n",
    "    \n",
    "    if not best_model_path.exists():\n",
    "        print(f\"❌ Best model not found: {best_model_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load best model\n",
    "        best_model = YOLO(str(best_model_path))\n",
    "        print(f\"✅ Best model loaded from: {best_model_path}\")\n",
    "        \n",
    "        # Run validation\n",
    "        print(\"\\n🎯 Running validation on test set...\")\n",
    "        val_results = best_model.val(data=config.data_yaml)\n",
    "        \n",
    "        # Display validation metrics\n",
    "        if hasattr(val_results, 'box'):\n",
    "            box_metrics = val_results.box\n",
    "            print(\"\\n📊 Validation Metrics:\")\n",
    "            print(f\"  mAP@0.5: {box_metrics.map50:.4f}\")\n",
    "            print(f\"  mAP@0.5:0.95: {box_metrics.map:.4f}\")\n",
    "            print(f\"  Precision: {box_metrics.mp:.4f}\")\n",
    "            print(f\"  Recall: {box_metrics.mr:.4f}\")\n",
    "        \n",
    "        return best_model, val_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Validation failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Run validation if training was successful\n",
    "if training_results:\n",
    "    best_model, validation_results = validate_trained_model(config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping validation - training was not completed\")\n",
    "    best_model, validation_results = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference-header"
   },
   "source": "## 🔍 ステップ9: モデル推論とテスト",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-inference"
   },
   "outputs": [],
   "source": [
    "# Test model inference on sample images\n",
    "def test_model_inference(model, config, num_samples=4):\n",
    "    if model is None:\n",
    "        print(\"❌ No model available for testing\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🔍 Testing model inference on {num_samples} sample images...\")\n",
    "    \n",
    "    # Get test images\n",
    "    test_images_dir = Path('datasets/test/images')\n",
    "    if not test_images_dir.exists():\n",
    "        # Fallback to validation images\n",
    "        test_images_dir = Path('datasets/valid/images')\n",
    "    \n",
    "    if not test_images_dir.exists():\n",
    "        print(\"❌ No test images found\")\n",
    "        return\n",
    "    \n",
    "    # Get sample images\n",
    "    image_files = list(test_images_dir.glob('*.[jp][pn]g'))\n",
    "    if len(image_files) == 0:\n",
    "        print(\"❌ No image files found\")\n",
    "        return\n",
    "    \n",
    "    sample_images = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    # Create subplot for results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Run inference\n",
    "            results = model(str(img_path))\n",
    "            \n",
    "            # Get annotated image\n",
    "            annotated_img = results[0].plot()\n",
    "            \n",
    "            # Convert BGR to RGB for matplotlib\n",
    "            annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display image\n",
    "            axes[i].imshow(annotated_img_rgb)\n",
    "            \n",
    "            # Get detection info\n",
    "            detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "            confidence = results[0].boxes.conf.max().item() if detections > 0 else 0\n",
    "            \n",
    "            axes[i].set_title(f\"{img_path.name}\\nDetections: {detections}, Max Conf: {confidence:.3f}\", \n",
    "                            fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {img_path.name}: {e}\")\n",
    "            axes[i].text(0.5, 0.5, f\"Error: {str(e)[:50]}...\", \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(sample_images), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('🔍 Model Inference Results', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Test inference\n",
    "if best_model:\n",
    "    test_model_inference(best_model, config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping inference test - no trained model available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-header"
   },
   "source": "## 💾 ステップ10: モデルエクスポートとダウンロード",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-model"
   },
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "def export_trained_model(model, config, formats=['onnx', 'torchscript']):\n",
    "    if model is None:\n",
    "        print(\"❌ No model available for export\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📦 Exporting model to formats: {formats}\")\n",
    "    \n",
    "    exported_files = []\n",
    "    \n",
    "    for format_type in formats:\n",
    "        try:\n",
    "            print(f\"\\n🔄 Exporting to {format_type.upper()}...\")\n",
    "            export_path = model.export(format=format_type, imgsz=config.image_size)\n",
    "            exported_files.append(export_path)\n",
    "            print(f\"✅ {format_type.upper()} export successful: {export_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {format_type.upper()} export failed: {e}\")\n",
    "    \n",
    "    if exported_files:\n",
    "        print(f\"\\n🎉 Successfully exported {len(exported_files)} model formats\")\n",
    "        for file_path in exported_files:\n",
    "            print(f\"  📄 {file_path}\")\n",
    "    \n",
    "    return exported_files\n",
    "\n",
    "# Export model\n",
    "if best_model:\n",
    "    exported_models = export_trained_model(best_model, config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping model export - no trained model available\")\n",
    "    exported_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy-to-drive"
   },
   "outputs": [],
   "source": [
    "# Copy results to Google Drive\n",
    "def copy_results_to_drive(config):\n",
    "    print(\"💾 Copying training results to Google Drive...\")\n",
    "    \n",
    "    # Source directory\n",
    "    source_dir = Path(config.project_name) / config.experiment_name\n",
    "    \n",
    "    # Destination directory in Google Drive\n",
    "    drive_dir = Path('/content/drive/MyDrive/insect_detection_training/results') / config.experiment_name\n",
    "    \n",
    "    if not source_dir.exists():\n",
    "        print(f\"❌ Source directory not found: {source_dir}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Create destination directory\n",
    "        drive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy entire results directory\n",
    "        import shutil\n",
    "        shutil.copytree(source_dir, drive_dir, dirs_exist_ok=True)\n",
    "        \n",
    "        print(f\"✅ Results copied to: {drive_dir}\")\n",
    "        \n",
    "        # List important files\n",
    "        important_files = [\n",
    "            'weights/best.pt',\n",
    "            'weights/last.pt', \n",
    "            'results.png',\n",
    "            'confusion_matrix.png'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n📁 Important files in Google Drive:\")\n",
    "        for file_path in important_files:\n",
    "            full_path = drive_dir / file_path\n",
    "            if full_path.exists():\n",
    "                size_mb = full_path.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  ✅ {file_path} ({size_mb:.1f} MB)\")\n",
    "            else:\n",
    "                print(f\"  ❌ {file_path} (not found)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error copying to Google Drive: {e}\")\n",
    "        return False\n",
    "\n",
    "# Copy results to Google Drive\n",
    "if training_results:\n",
    "    copy_success = copy_results_to_drive(config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping copy to Google Drive - no training results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "# Download trained models to local computer\n",
    "def download_models(config):\n",
    "    print(\"⬇️ Preparing model files for download...\")\n",
    "    \n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    weights_dir = results_dir / 'weights'\n",
    "    \n",
    "    if not weights_dir.exists():\n",
    "        print(f\"❌ Weights directory not found: {weights_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Files to download\n",
    "    download_files = {\n",
    "        'best.pt': 'Best model weights',\n",
    "        'last.pt': 'Last epoch weights'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n📥 Available for download:\")\n",
    "    \n",
    "    for filename, description in download_files.items():\n",
    "        file_path = weights_dir / filename\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  📄 {filename}: {description} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            # Trigger download\n",
    "            try:\n",
    "                files.download(str(file_path))\n",
    "                print(f\"  ✅ {filename} download initiated\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ Error downloading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"  ❌ {filename}: Not found\")\n",
    "    \n",
    "    # Also download results plot\n",
    "    results_plot = results_dir / 'results.png'\n",
    "    if results_plot.exists():\n",
    "        try:\n",
    "            files.download(str(results_plot))\n",
    "            print(f\"  ✅ results.png download initiated\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error downloading results.png: {e}\")\n",
    "\n",
    "# Download models\n",
    "if training_results:\n",
    "    download_models(config)\n",
    "else:\n",
    "    print(\"⚠️ No models available for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-header"
   },
   "source": "## 📋 ステップ11: トレーニングサマリーと次のステップ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-summary"
   },
   "outputs": [],
   "source": [
    "# Generate training summary\n",
    "def generate_training_summary(config, training_results, validation_results):\n",
    "    print(\"📋 TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"🎯 Project: {config.project_name}/{config.experiment_name}\")\n",
    "    print(f\"🤖 Model: {config.pretrained_model}\")\n",
    "    print(f\"📊 Dataset: {config.data_yaml}\")\n",
    "    print(f\"⚙️ Configuration:\")\n",
    "    print(f\"   - Epochs: {config.epochs}\")\n",
    "    print(f\"   - Batch Size: {config.batch_size}\")\n",
    "    print(f\"   - Image Size: {config.image_size}\")\n",
    "    print(f\"   - Device: {config.device}\")\n",
    "    \n",
    "    # Training status\n",
    "    if training_results:\n",
    "        print(f\"\\n✅ Training Status: COMPLETED\")\n",
    "        \n",
    "        # Validation metrics\n",
    "        if validation_results and hasattr(validation_results, 'box'):\n",
    "            box_metrics = validation_results.box\n",
    "            print(f\"\\n📊 Final Metrics:\")\n",
    "            print(f\"   - mAP@0.5: {box_metrics.map50:.4f}\")\n",
    "            print(f\"   - mAP@0.5:0.95: {box_metrics.map:.4f}\")\n",
    "            print(f\"   - Precision: {box_metrics.mp:.4f}\")\n",
    "            print(f\"   - Recall: {box_metrics.mr:.4f}\")\n",
    "            \n",
    "            # Performance evaluation\n",
    "            if box_metrics.map50 >= 0.7:\n",
    "                print(f\"   🎉 EXCELLENT: Model meets target performance (mAP@0.5 ≥ 0.7)\")\n",
    "            elif box_metrics.map50 >= 0.5:\n",
    "                print(f\"   ✅ GOOD: Model shows good performance (mAP@0.5 ≥ 0.5)\")\n",
    "            else:\n",
    "                print(f\"   ⚠️ FAIR: Model needs improvement (mAP@0.5 < 0.5)\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Training Status: FAILED or INCOMPLETE\")\n",
    "    \n",
    "    # File locations\n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    drive_dir = Path('/content/drive/MyDrive/insect_detection_training/results') / config.experiment_name\n",
    "    \n",
    "    print(f\"\\n📁 Output Locations:\")\n",
    "    print(f\"   - Local: {results_dir}\")\n",
    "    print(f\"   - Google Drive: {drive_dir}\")\n",
    "    \n",
    "    # Next steps\n",
    "    print(f\"\\n🚀 Next Steps:\")\n",
    "    print(f\"   1. Download model files (best.pt) for deployment\")\n",
    "    print(f\"   2. Test model on new images\")\n",
    "    print(f\"   3. Deploy to production environment\")\n",
    "    print(f\"   4. Monitor performance on real data\")\n",
    "    \n",
    "    if training_results:\n",
    "        print(f\"\\n💡 Optimization Tips:\")\n",
    "        if validation_results and hasattr(validation_results, 'box'):\n",
    "            if validation_results.box.map50 < 0.7:\n",
    "                print(f\"   - Try training for more epochs\")\n",
    "                print(f\"   - Increase model size (yolov8s or yolov8m)\")\n",
    "                print(f\"   - Add more training data\")\n",
    "                print(f\"   - Adjust data augmentation\")\n",
    "            else:\n",
    "                print(f\"   - Model performance is good!\")\n",
    "                print(f\"   - Consider model compression for deployment\")\n",
    "                print(f\"   - Test on edge devices (Raspberry Pi)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Generate summary\n",
    "generate_training_summary(config, training_results, validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usage-examples"
   },
   "outputs": [],
   "source": [
    "# Usage examples for trained model\n",
    "def show_usage_examples(config):\n",
    "    print(\"💻 USAGE EXAMPLES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model_path = f\"{config.project_name}/{config.experiment_name}/weights/best.pt\"\n",
    "    \n",
    "    print(\"\\n🐍 Python Usage:\")\n",
    "    print(\"```python\")\n",
    "    print(\"from ultralytics import YOLO\")\n",
    "    print(\"\")\n",
    "    print(f\"# Load trained model\")\n",
    "    print(f\"model = YOLO('{model_path}')\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference on single image\")\n",
    "    print(\"results = model('path/to/image.jpg')\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference on multiple images\")\n",
    "    print(\"results = model(['img1.jpg', 'img2.jpg'])\")\n",
    "    print(\"\")\n",
    "    print(\"# Save results with annotations\")\n",
    "    print(\"for r in results:\")\n",
    "    print(\"    r.save(filename='result.jpg')\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n🖥️ Command Line Usage:\")\n",
    "    print(\"```bash\")\n",
    "    print(f\"# Single image prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=image.jpg\")\n",
    "    print(\"\")\n",
    "    print(f\"# Batch prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=images_folder/\")\n",
    "    print(\"\")\n",
    "    print(f\"# Video prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=video.mp4\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n🌐 Integration with detect_insect.py:\")\n",
    "    print(\"```bash\")\n",
    "    print(f\"# Use trained model with detection script\")\n",
    "    print(f\"python detect_insect.py \\\\\")\n",
    "    print(f\"    --input input_images/ \\\\\")\n",
    "    print(f\"    --output output_images/ \\\\\")\n",
    "    print(f\"    --model {model_path}\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n📱 Export for Edge Deployment:\")\n",
    "    print(\"```python\")\n",
    "    print(\"# Export to ONNX for cross-platform deployment\")\n",
    "    print(f\"model = YOLO('{model_path}')\")\n",
    "    print(\"model.export(format='onnx')\")\n",
    "    print(\"\")\n",
    "    print(\"# Export to TensorRT for NVIDIA GPUs\")\n",
    "    print(\"model.export(format='engine')\")\n",
    "    print(\"```\")\n",
    "\n",
    "# Show usage examples\n",
    "if training_results:\n",
    "    show_usage_examples(config)\n",
    "else:\n",
    "    print(\"⚠️ No usage examples available - training was not completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": "---\n\n## 🎉 トレーニング完了！\n\n**おめでとうございます！** 昆虫検出のためのYOLOv8トレーニングパイプラインが正常に完了しました。\n\n### 📋 達成した内容:\n- ✅ GPU加速トレーニング環境のセットアップ\n- ✅ カブトムシ検出データセットの準備と検証\n- ✅ カスタムYOLOv8モデルの訓練\n- ✅ モデル性能の評価\n- ✅ 展開用モデルのエクスポート\n- ✅ 結果のGoogle Driveへの保存\n\n### 🚀 次のステップ:\n1. **訓練済みモデルのダウンロード** (`best.pt`) をローカルで使用\n2. **新しいカブトムシ画像でのテスト**\n3. **提供された使用例を使用した本番環境への展開**\n4. **性能の監視** と必要に応じた再訓練\n\n### 📚 リソース:\n- [YOLOv8 ドキュメント](https://docs.ultralytics.com/)\n- [モデル展開ガイド](https://docs.ultralytics.com/modes/export/)\n- [性能最適化](https://docs.ultralytics.com/guides/model-optimization/)\n\n---\n\n*🐛 楽しいカブトムシ検出を！ 🐛*",
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}