{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 🐛 YOLOv8 Insect Detection Training on Google Colab\n",
    "\n",
    "**Project**: Insect Detection Training Project  \n",
    "**Purpose**: Train custom YOLOv8 models for beetle detection using Roboflow dataset  \n",
    "**Environment**: Google Colaboratory with GPU acceleration  \n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Overview\n",
    "\n",
    "This notebook provides an interactive training pipeline for YOLOv8 insect detection models. It includes:\n",
    "\n",
    "- ✅ Automated environment setup\n",
    "- ✅ GPU configuration and verification\n",
    "- ✅ Dataset preparation and validation\n",
    "- ✅ Interactive model training\n",
    "- ✅ Real-time progress monitoring\n",
    "- ✅ Model evaluation and export\n",
    "- ✅ Results visualization\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ Quick Start\n",
    "\n",
    "1. **Enable GPU**: Go to Runtime → Change runtime type → Select GPU\n",
    "2. **Run all cells**: Click Runtime → Run all\n",
    "3. **Upload dataset**: Follow prompts to upload your dataset\n",
    "4. **Monitor training**: Watch real-time training progress\n",
    "5. **Download results**: Save trained models to Google Drive\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 🛠️ Step 1: Environment Setup and Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-libraries"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "print(\"🔧 Installing required libraries...\")\n",
    "\n",
    "!pip install ultralytics roboflow supervision\n",
    "!pip install --upgrade torch torchvision\n",
    "\n",
    "print(\"✅ Installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display, HTML, clear_output\n",
    "import cv2\n",
    "\n",
    "# Google Colab specific\n",
    "from google.colab import files, drive\n",
    "import yaml\n",
    "\n",
    "print(\"📚 Libraries imported successfully!\")\n",
    "print(f\"🐍 Python version: {sys.version}\")\n",
    "print(f\"🔥 PyTorch version: {torch.__version__}\")\n",
    "print(f\"👁️ OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu-header"
   },
   "source": [
    "## 🚀 Step 2: GPU Configuration and System Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability and configuration\n",
    "def check_gpu_setup():\n",
    "    print(\"🔍 Checking GPU configuration...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check CUDA availability\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA Available: {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"GPU Count: {device_count}\")\n",
    "        \n",
    "        for i in range(device_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "        \n",
    "        # Set device\n",
    "        device = torch.device('cuda:0')\n",
    "        print(f\"\\n✅ Using device: {device}\")\n",
    "        \n",
    "        # Test GPU with a simple operation\n",
    "        test_tensor = torch.rand(1000, 1000).to(device)\n",
    "        result = torch.mm(test_tensor, test_tensor.t())\n",
    "        print(\"✅ GPU test operation successful!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ GPU not available. Training will use CPU (slower).\")\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    return device\n",
    "\n",
    "# Run GPU check\n",
    "training_device = check_gpu_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "system-info"
   },
   "outputs": [],
   "source": [
    "# Display system information\n",
    "def display_system_info():\n",
    "    print(\"💻 System Information\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # CPU information\n",
    "    print(f\"CPU cores: {os.cpu_count()}\")\n",
    "    \n",
    "    # Memory information (approximate)\n",
    "    import psutil\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"RAM: {memory.total / 1e9:.1f} GB (Available: {memory.available / 1e9:.1f} GB)\")\n",
    "    \n",
    "    # Disk space\n",
    "    disk = psutil.disk_usage('/')\n",
    "    print(f\"Disk: {disk.total / 1e9:.1f} GB (Free: {disk.free / 1e9:.1f} GB)\")\n",
    "    \n",
    "    print(\"\\n🔧 Software Versions\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Python: {sys.version.split()[0]}\")\n",
    "    print(f\"PyTorch: {torch.__version__}\")\n",
    "    print(f\"Torchvision: {torchvision.__version__}\")\n",
    "    print(f\"OpenCV: {cv2.__version__}\")\n",
    "    print(f\"NumPy: {np.__version__}\")\n",
    "    \n",
    "display_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive-header"
   },
   "source": [
    "## 📁 Step 3: Google Drive Integration and Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "print(\"📁 Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Google Drive\n",
    "project_dir = Path('/content/drive/MyDrive/insect_detection_training')\n",
    "project_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create subdirectories\n",
    "(project_dir / 'datasets').mkdir(exist_ok=True)\n",
    "(project_dir / 'models').mkdir(exist_ok=True)\n",
    "(project_dir / 'results').mkdir(exist_ok=True)\n",
    "(project_dir / 'logs').mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"✅ Project directory created: {project_dir}\")\n",
    "print(f\"📂 Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/content')\n",
    "print(f\"📁 Changed to working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-header"
   },
   "source": [
    "## 📊 Step 4: Dataset Preparation and Upload\n",
    "\n",
    "### Option A: Upload from Local Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-dataset"
   },
   "outputs": [],
   "source": [
    "# Option A: Upload dataset from local computer\n",
    "def upload_dataset_local():\n",
    "    print(\"📤 Upload your dataset ZIP file\")\n",
    "    print(\"Expected structure inside ZIP:\")\n",
    "    print(\"\"\"\n",
    "    dataset.zip\n",
    "    ├── train/\n",
    "    │   ├── images/\n",
    "    │   └── labels/\n",
    "    ├── valid/\n",
    "    │   ├── images/\n",
    "    │   └── labels/\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   └── labels/\n",
    "    └── data.yaml\n",
    "    \"\"\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Extract uploaded files\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"📦 Extracting {filename}...\")\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall('datasets')\n",
    "            print(\"✅ Dataset extracted successfully!\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"❌ No ZIP file found. Please upload a ZIP file containing your dataset.\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Uncomment the line below to upload dataset\n",
    "# upload_success = upload_dataset_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roboflow-header"
   },
   "source": [
    "### Option B: Download from Roboflow (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roboflow-download"
   },
   "outputs": [],
   "source": [
    "# Option B: Download from Roboflow\n",
    "def download_roboflow_dataset():\n",
    "    print(\"🤖 Downloading beetle dataset from Roboflow...\")\n",
    "    \n",
    "    try:\n",
    "        from roboflow import Roboflow\n",
    "        \n",
    "        # Initialize Roboflow (you may need to set API key)\n",
    "        # Get your API key from: https://app.roboflow.com/settings/api\n",
    "        print(\"🔑 Please enter your Roboflow API key (or press Enter to skip):\")\n",
    "        api_key = input(\"API Key: \").strip()\n",
    "        \n",
    "        if api_key:\n",
    "            rf = Roboflow(api_key=api_key)\n",
    "            project = rf.workspace(\"z-algae-bilby\").project(\"beetle\")\n",
    "            dataset = project.version(1).download(\"yolov8\", location=\"datasets\")\n",
    "            print(\"✅ Dataset downloaded from Roboflow!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"⚠️ No API key provided. You can download manually from:\")\n",
    "            print(\"https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error downloading from Roboflow: {e}\")\n",
    "        print(\"💡 Alternative: Download manually and upload using Option A\")\n",
    "        return False\n",
    "\n",
    "# Download from Roboflow\n",
    "download_success = download_roboflow_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "manual-setup-header"
   },
   "source": [
    "### Option C: Manual Dataset Setup (For Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "manual-dataset"
   },
   "outputs": [],
   "source": [
    "# Option C: Create sample dataset structure for testing\n",
    "def create_sample_dataset():\n",
    "    print(\"🧪 Creating sample dataset structure for testing...\")\n",
    "    \n",
    "    # Create directory structure\n",
    "    base_dir = Path('datasets')\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        (base_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (base_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create sample data.yaml\n",
    "    data_yaml = {\n",
    "        'train': './train/images',\n",
    "        'val': './valid/images', \n",
    "        'test': './test/images',\n",
    "        'nc': 1,\n",
    "        'names': ['beetle'],\n",
    "        'roboflow': {\n",
    "            'workspace': 'z-algae-bilby',\n",
    "            'project': 'beetle',\n",
    "            'version': 1,\n",
    "            'license': 'CC BY 4.0',\n",
    "            'url': 'https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(base_dir / 'data.yaml', 'w') as f:\n",
    "        yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "    \n",
    "    print(\"✅ Sample dataset structure created!\")\n",
    "    print(\"⚠️ Note: This is just a structure. You still need to add actual images and labels.\")\n",
    "    return True\n",
    "\n",
    "# Uncomment to create sample structure\n",
    "# create_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validation-header"
   },
   "source": [
    "## ✅ Step 5: Dataset Validation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate-dataset"
   },
   "outputs": [],
   "source": [
    "# Validate dataset structure and contents\n",
    "def validate_dataset(dataset_path='datasets'):\n",
    "    print(\"🔍 Validating dataset structure...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    dataset_dir = Path(dataset_path)\n",
    "    \n",
    "    # Check if data.yaml exists\n",
    "    data_yaml_path = dataset_dir / 'data.yaml'\n",
    "    if not data_yaml_path.exists():\n",
    "        print(\"❌ data.yaml not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Load and display data.yaml\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"📄 Dataset Configuration (data.yaml):\")\n",
    "    for key, value in data_config.items():\n",
    "        if key != 'roboflow':\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Check directory structure and count files\n",
    "    results = {}\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        images_dir = dataset_dir / split / 'images'\n",
    "        labels_dir = dataset_dir / split / 'labels'\n",
    "        \n",
    "        if images_dir.exists() and labels_dir.exists():\n",
    "            image_files = list(images_dir.glob('*.[jp][pn]g')) + list(images_dir.glob('*.jpeg'))\n",
    "            label_files = list(labels_dir.glob('*.txt'))\n",
    "            \n",
    "            results[split] = {\n",
    "                'images': len(image_files),\n",
    "                'labels': len(label_files)\n",
    "            }\n",
    "            \n",
    "            status = \"✅\" if len(image_files) == len(label_files) and len(image_files) > 0 else \"⚠️\"\n",
    "            print(f\"{status} {split.upper()}: {len(image_files)} images, {len(label_files)} labels\")\n",
    "        else:\n",
    "            print(f\"❌ {split.upper()}: Directory not found\")\n",
    "            results[split] = {'images': 0, 'labels': 0}\n",
    "    \n",
    "    # Calculate total\n",
    "    total_images = sum(split['images'] for split in results.values())\n",
    "    total_labels = sum(split['labels'] for split in results.values())\n",
    "    \n",
    "    print(f\"\\n📊 TOTAL: {total_images} images, {total_labels} labels\")\n",
    "    \n",
    "    if total_images > 0 and total_images == total_labels:\n",
    "        print(\"✅ Dataset validation successful!\")\n",
    "        return True, data_config, results\n",
    "    else:\n",
    "        print(\"❌ Dataset validation failed!\")\n",
    "        return False, None, None\n",
    "\n",
    "# Run validation\n",
    "validation_success, dataset_config, dataset_stats = validate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-dataset"
   },
   "outputs": [],
   "source": [
    "# Visualize dataset statistics\n",
    "def visualize_dataset_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"❌ No dataset statistics to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 Dataset Statistics Visualization\")\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Images per split\n",
    "    splits = list(stats.keys())\n",
    "    image_counts = [stats[split]['images'] for split in splits]\n",
    "    \n",
    "    bars1 = ax1.bar(splits, image_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    ax1.set_title('Images per Split', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Images')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars1, image_counts):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Split distribution pie chart\n",
    "    total = sum(image_counts)\n",
    "    percentages = [count/total*100 for count in image_counts]\n",
    "    \n",
    "    ax2.pie(percentages, labels=[f'{split}\\n({count} images)' for split, count in zip(splits, image_counts)], \n",
    "            autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    ax2.set_title('Dataset Split Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📈 Dataset Summary:\")\n",
    "    print(f\"Total Images: {total}\")\n",
    "    for split, count in zip(splits, image_counts):\n",
    "        percentage = count/total*100\n",
    "        print(f\"{split.upper()}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize if validation was successful\n",
    "if validation_success:\n",
    "    visualize_dataset_stats(dataset_stats)\n",
    "else:\n",
    "    print(\"⚠️ Cannot visualize dataset - validation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample-images"
   },
   "outputs": [],
   "source": [
    "# Display sample images from dataset\n",
    "def display_sample_images(dataset_path='datasets', num_samples=6):\n",
    "    if not validation_success:\n",
    "        print(\"⚠️ Cannot display samples - dataset validation failed\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🖼️ Displaying {num_samples} sample images from training set\")\n",
    "    \n",
    "    dataset_dir = Path(dataset_path)\n",
    "    train_images = list((dataset_dir / 'train' / 'images').glob('*.[jp][pn]g'))\n",
    "    \n",
    "    if len(train_images) == 0:\n",
    "        print(\"❌ No images found in training set\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    sample_images = np.random.choice(train_images, min(num_samples, len(train_images)), replace=False)\n",
    "    \n",
    "    # Create subplot\n",
    "    cols = 3\n",
    "    rows = (num_samples + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    \n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Load and display image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f\"Sample {i+1}: {img_path.name}\", fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(sample_images), rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "display_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-header"
   },
   "source": [
    "## 🎯 Step 6: Training Configuration and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-config"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration class\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Model configuration\n",
    "        self.model_size = 'n'  # n, s, m, l, x (nano, small, medium, large, extra-large)\n",
    "        self.pretrained_model = f'yolov8{self.model_size}.pt'\n",
    "        \n",
    "        # Training parameters\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 16  # Adjust based on GPU memory\n",
    "        self.image_size = 640\n",
    "        self.device = 'auto'  # auto, cpu, 0, 1, etc.\n",
    "        \n",
    "        # Data configuration\n",
    "        self.data_yaml = 'datasets/data.yaml'\n",
    "        \n",
    "        # Output configuration\n",
    "        self.project_name = 'training_results'\n",
    "        self.experiment_name = 'beetle_detection_colab'\n",
    "        \n",
    "        # Advanced settings\n",
    "        self.patience = 50  # Early stopping patience\n",
    "        self.save_period = 10  # Save checkpoint every N epochs\n",
    "        self.workers = 2  # Number of dataloader workers\n",
    "        \n",
    "        # Optimization\n",
    "        self.optimizer = 'AdamW'  # SGD, Adam, AdamW\n",
    "        self.lr0 = 0.01  # Initial learning rate\n",
    "        self.weight_decay = 0.0005\n",
    "        \n",
    "    def display_config(self):\n",
    "        \"\"\"Display current configuration\"\"\"\n",
    "        print(\"🎯 Training Configuration\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Model: {self.pretrained_model}\")\n",
    "        print(f\"Epochs: {self.epochs}\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(f\"Image Size: {self.image_size}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Dataset: {self.data_yaml}\")\n",
    "        print(f\"Project: {self.project_name}/{self.experiment_name}\")\n",
    "        print(f\"Optimizer: {self.optimizer}\")\n",
    "        print(f\"Learning Rate: {self.lr0}\")\n",
    "        print(f\"Weight Decay: {self.weight_decay}\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "# Create configuration\n",
    "config = TrainingConfig()\n",
    "config.display_config()\n",
    "\n",
    "# GPU memory optimization\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"\\n🎮 GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Adjust batch size based on GPU memory\n",
    "    if gpu_memory < 8:\n",
    "        config.batch_size = 8\n",
    "        print(\"⚡ Reduced batch size to 8 for GPU memory optimization\")\n",
    "    elif gpu_memory >= 16:\n",
    "        config.batch_size = 32\n",
    "        print(\"🚀 Increased batch size to 32 for better GPU utilization\")\n",
    "    \n",
    "print(f\"\\n📊 Final Batch Size: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-training-header"
   },
   "source": [
    "## 🚀 Step 7: Model Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "def load_pretrained_model(model_name):\n",
    "    print(f\"📥 Loading pre-trained model: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_name)\n",
    "        print(f\"✅ Model loaded successfully!\")\n",
    "        \n",
    "        # Display model info\n",
    "        print(f\"\\n📋 Model Information:\")\n",
    "        print(f\"Model file: {model_name}\")\n",
    "        print(f\"Task: {model.task}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the model\n",
    "model = load_pretrained_model(config.pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-execution"
   },
   "outputs": [],
   "source": [
    "# Execute model training\n",
    "def train_model(model, config):\n",
    "    if model is None:\n",
    "        print(\"❌ Cannot start training - model not loaded\")\n",
    "        return None\n",
    "    \n",
    "    if not validation_success:\n",
    "        print(\"❌ Cannot start training - dataset validation failed\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🚀 Starting model training...\")\n",
    "    print(\"⏱️ This may take a while depending on your configuration\")\n",
    "    print(\"📊 Training progress will be displayed below\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Start training\n",
    "        results = model.train(\n",
    "            data=config.data_yaml,\n",
    "            epochs=config.epochs,\n",
    "            batch=config.batch_size,\n",
    "            imgsz=config.image_size,\n",
    "            device=config.device,\n",
    "            project=config.project_name,\n",
    "            name=config.experiment_name,\n",
    "            save=True,\n",
    "            save_period=config.save_period,\n",
    "            patience=config.patience,\n",
    "            workers=config.workers,\n",
    "            optimizer=config.optimizer,\n",
    "            lr0=config.lr0,\n",
    "            weight_decay=config.weight_decay,\n",
    "            val=True,\n",
    "            plots=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Calculate training time\n",
    "        training_time = time.time() - start_time\n",
    "        hours = int(training_time // 3600)\n",
    "        minutes = int((training_time % 3600) // 60)\n",
    "        seconds = int(training_time % 60)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"✅ Training completed successfully!\")\n",
    "        print(f\"⏱️ Total training time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "        print(f\"📁 Results saved to: {config.project_name}/{config.experiment_name}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Start training (this will take a while!)\n",
    "print(\"⚠️ Warning: Training will start in 5 seconds...\")\n",
    "time.sleep(5)\n",
    "\n",
    "training_results = train_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": [
    "## 📊 Step 8: Training Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display-results"
   },
   "outputs": [],
   "source": [
    "# Display training results\n",
    "def display_training_results(results, config):\n",
    "    if results is None:\n",
    "        print(\"❌ No training results to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 Training Results Summary\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Results directory\n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    \n",
    "    # Display key metrics if available\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        metrics = results.results_dict\n",
    "        print(\"🎯 Final Metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    # Check for results plots\n",
    "    plots_to_show = [\n",
    "        ('results.png', '📈 Training/Validation Curves'),\n",
    "        ('confusion_matrix.png', '🎯 Confusion Matrix'),\n",
    "        ('labels.jpg', '📊 Label Distribution'),\n",
    "        ('val_batch0_pred.jpg', '🔍 Validation Predictions')\n",
    "    ]\n",
    "    \n",
    "    for plot_file, title in plots_to_show:\n",
    "        plot_path = results_dir / plot_file\n",
    "        if plot_path.exists():\n",
    "            print(f\"\\n{title}\")\n",
    "            display(Image(str(plot_path)))\n",
    "        else:\n",
    "            print(f\"⚠️ {title} not found: {plot_path}\")\n",
    "\n",
    "# Display results\n",
    "if training_results:\n",
    "    display_training_results(training_results, config)\n",
    "else:\n",
    "    print(\"⚠️ No training results available to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-validation"
   },
   "outputs": [],
   "source": [
    "# Load best model and run validation\n",
    "def validate_trained_model(config):\n",
    "    print(\"🧪 Loading best model for validation...\")\n",
    "    \n",
    "    # Path to best model\n",
    "    best_model_path = Path(config.project_name) / config.experiment_name / 'weights' / 'best.pt'\n",
    "    \n",
    "    if not best_model_path.exists():\n",
    "        print(f\"❌ Best model not found: {best_model_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load best model\n",
    "        best_model = YOLO(str(best_model_path))\n",
    "        print(f\"✅ Best model loaded from: {best_model_path}\")\n",
    "        \n",
    "        # Run validation\n",
    "        print(\"\\n🎯 Running validation on test set...\")\n",
    "        val_results = best_model.val(data=config.data_yaml)\n",
    "        \n",
    "        # Display validation metrics\n",
    "        if hasattr(val_results, 'box'):\n",
    "            box_metrics = val_results.box\n",
    "            print(\"\\n📊 Validation Metrics:\")\n",
    "            print(f\"  mAP@0.5: {box_metrics.map50:.4f}\")\n",
    "            print(f\"  mAP@0.5:0.95: {box_metrics.map:.4f}\")\n",
    "            print(f\"  Precision: {box_metrics.mp:.4f}\")\n",
    "            print(f\"  Recall: {box_metrics.mr:.4f}\")\n",
    "        \n",
    "        return best_model, val_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Validation failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Run validation if training was successful\n",
    "if training_results:\n",
    "    best_model, validation_results = validate_trained_model(config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping validation - training was not completed\")\n",
    "    best_model, validation_results = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference-header"
   },
   "source": [
    "## 🔍 Step 9: Model Inference and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-inference"
   },
   "outputs": [],
   "source": [
    "# Test model inference on sample images\n",
    "def test_model_inference(model, config, num_samples=4):\n",
    "    if model is None:\n",
    "        print(\"❌ No model available for testing\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🔍 Testing model inference on {num_samples} sample images...\")\n",
    "    \n",
    "    # Get test images\n",
    "    test_images_dir = Path('datasets/test/images')\n",
    "    if not test_images_dir.exists():\n",
    "        # Fallback to validation images\n",
    "        test_images_dir = Path('datasets/valid/images')\n",
    "    \n",
    "    if not test_images_dir.exists():\n",
    "        print(\"❌ No test images found\")\n",
    "        return\n",
    "    \n",
    "    # Get sample images\n",
    "    image_files = list(test_images_dir.glob('*.[jp][pn]g'))\n",
    "    if len(image_files) == 0:\n",
    "        print(\"❌ No image files found\")\n",
    "        return\n",
    "    \n",
    "    sample_images = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    # Create subplot for results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Run inference\n",
    "            results = model(str(img_path))\n",
    "            \n",
    "            # Get annotated image\n",
    "            annotated_img = results[0].plot()\n",
    "            \n",
    "            # Convert BGR to RGB for matplotlib\n",
    "            annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display image\n",
    "            axes[i].imshow(annotated_img_rgb)\n",
    "            \n",
    "            # Get detection info\n",
    "            detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "            confidence = results[0].boxes.conf.max().item() if detections > 0 else 0\n",
    "            \n",
    "            axes[i].set_title(f\"{img_path.name}\\nDetections: {detections}, Max Conf: {confidence:.3f}\", \n",
    "                            fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {img_path.name}: {e}\")\n",
    "            axes[i].text(0.5, 0.5, f\"Error: {str(e)[:50]}...\", \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(sample_images), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('🔍 Model Inference Results', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Test inference\n",
    "if best_model:\n",
    "    test_model_inference(best_model, config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping inference test - no trained model available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-header"
   },
   "source": [
    "## 💾 Step 10: Model Export and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-model"
   },
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "def export_trained_model(model, config, formats=['onnx', 'torchscript']):\n",
    "    if model is None:\n",
    "        print(\"❌ No model available for export\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📦 Exporting model to formats: {formats}\")\n",
    "    \n",
    "    exported_files = []\n",
    "    \n",
    "    for format_type in formats:\n",
    "        try:\n",
    "            print(f\"\\n🔄 Exporting to {format_type.upper()}...\")\n",
    "            export_path = model.export(format=format_type, imgsz=config.image_size)\n",
    "            exported_files.append(export_path)\n",
    "            print(f\"✅ {format_type.upper()} export successful: {export_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {format_type.upper()} export failed: {e}\")\n",
    "    \n",
    "    if exported_files:\n",
    "        print(f\"\\n🎉 Successfully exported {len(exported_files)} model formats\")\n",
    "        for file_path in exported_files:\n",
    "            print(f\"  📄 {file_path}\")\n",
    "    \n",
    "    return exported_files\n",
    "\n",
    "# Export model\n",
    "if best_model:\n",
    "    exported_models = export_trained_model(best_model, config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping model export - no trained model available\")\n",
    "    exported_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy-to-drive"
   },
   "outputs": [],
   "source": [
    "# Copy results to Google Drive\n",
    "def copy_results_to_drive(config):\n",
    "    print(\"💾 Copying training results to Google Drive...\")\n",
    "    \n",
    "    # Source directory\n",
    "    source_dir = Path(config.project_name) / config.experiment_name\n",
    "    \n",
    "    # Destination directory in Google Drive\n",
    "    drive_dir = Path('/content/drive/MyDrive/insect_detection_training/results') / config.experiment_name\n",
    "    \n",
    "    if not source_dir.exists():\n",
    "        print(f\"❌ Source directory not found: {source_dir}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Create destination directory\n",
    "        drive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy entire results directory\n",
    "        import shutil\n",
    "        shutil.copytree(source_dir, drive_dir, dirs_exist_ok=True)\n",
    "        \n",
    "        print(f\"✅ Results copied to: {drive_dir}\")\n",
    "        \n",
    "        # List important files\n",
    "        important_files = [\n",
    "            'weights/best.pt',\n",
    "            'weights/last.pt', \n",
    "            'results.png',\n",
    "            'confusion_matrix.png'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n📁 Important files in Google Drive:\")\n",
    "        for file_path in important_files:\n",
    "            full_path = drive_dir / file_path\n",
    "            if full_path.exists():\n",
    "                size_mb = full_path.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  ✅ {file_path} ({size_mb:.1f} MB)\")\n",
    "            else:\n",
    "                print(f\"  ❌ {file_path} (not found)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error copying to Google Drive: {e}\")\n",
    "        return False\n",
    "\n",
    "# Copy results to Google Drive\n",
    "if training_results:\n",
    "    copy_success = copy_results_to_drive(config)\n",
    "else:\n",
    "    print(\"⚠️ Skipping copy to Google Drive - no training results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "# Download trained models to local computer\n",
    "def download_models(config):\n",
    "    print(\"⬇️ Preparing model files for download...\")\n",
    "    \n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    weights_dir = results_dir / 'weights'\n",
    "    \n",
    "    if not weights_dir.exists():\n",
    "        print(f\"❌ Weights directory not found: {weights_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Files to download\n",
    "    download_files = {\n",
    "        'best.pt': 'Best model weights',\n",
    "        'last.pt': 'Last epoch weights'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n📥 Available for download:\")\n",
    "    \n",
    "    for filename, description in download_files.items():\n",
    "        file_path = weights_dir / filename\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  📄 {filename}: {description} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            # Trigger download\n",
    "            try:\n",
    "                files.download(str(file_path))\n",
    "                print(f\"  ✅ {filename} download initiated\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ Error downloading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"  ❌ {filename}: Not found\")\n",
    "    \n",
    "    # Also download results plot\n",
    "    results_plot = results_dir / 'results.png'\n",
    "    if results_plot.exists():\n",
    "        try:\n",
    "            files.download(str(results_plot))\n",
    "            print(f\"  ✅ results.png download initiated\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error downloading results.png: {e}\")\n",
    "\n",
    "# Download models\n",
    "if training_results:\n",
    "    download_models(config)\n",
    "else:\n",
    "    print(\"⚠️ No models available for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-header"
   },
   "source": [
    "## 📋 Step 11: Training Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-summary"
   },
   "outputs": [],
   "source": [
    "# Generate training summary\n",
    "def generate_training_summary(config, training_results, validation_results):\n",
    "    print(\"📋 TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"🎯 Project: {config.project_name}/{config.experiment_name}\")\n",
    "    print(f\"🤖 Model: {config.pretrained_model}\")\n",
    "    print(f\"📊 Dataset: {config.data_yaml}\")\n",
    "    print(f\"⚙️ Configuration:\")\n",
    "    print(f\"   - Epochs: {config.epochs}\")\n",
    "    print(f\"   - Batch Size: {config.batch_size}\")\n",
    "    print(f\"   - Image Size: {config.image_size}\")\n",
    "    print(f\"   - Device: {config.device}\")\n",
    "    \n",
    "    # Training status\n",
    "    if training_results:\n",
    "        print(f\"\\n✅ Training Status: COMPLETED\")\n",
    "        \n",
    "        # Validation metrics\n",
    "        if validation_results and hasattr(validation_results, 'box'):\n",
    "            box_metrics = validation_results.box\n",
    "            print(f\"\\n📊 Final Metrics:\")\n",
    "            print(f\"   - mAP@0.5: {box_metrics.map50:.4f}\")\n",
    "            print(f\"   - mAP@0.5:0.95: {box_metrics.map:.4f}\")\n",
    "            print(f\"   - Precision: {box_metrics.mp:.4f}\")\n",
    "            print(f\"   - Recall: {box_metrics.mr:.4f}\")\n",
    "            \n",
    "            # Performance evaluation\n",
    "            if box_metrics.map50 >= 0.7:\n",
    "                print(f\"   🎉 EXCELLENT: Model meets target performance (mAP@0.5 ≥ 0.7)\")\n",
    "            elif box_metrics.map50 >= 0.5:\n",
    "                print(f\"   ✅ GOOD: Model shows good performance (mAP@0.5 ≥ 0.5)\")\n",
    "            else:\n",
    "                print(f\"   ⚠️ FAIR: Model needs improvement (mAP@0.5 < 0.5)\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Training Status: FAILED or INCOMPLETE\")\n",
    "    \n",
    "    # File locations\n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    drive_dir = Path('/content/drive/MyDrive/insect_detection_training/results') / config.experiment_name\n",
    "    \n",
    "    print(f\"\\n📁 Output Locations:\")\n",
    "    print(f\"   - Local: {results_dir}\")\n",
    "    print(f\"   - Google Drive: {drive_dir}\")\n",
    "    \n",
    "    # Next steps\n",
    "    print(f\"\\n🚀 Next Steps:\")\n",
    "    print(f\"   1. Download model files (best.pt) for deployment\")\n",
    "    print(f\"   2. Test model on new images\")\n",
    "    print(f\"   3. Deploy to production environment\")\n",
    "    print(f\"   4. Monitor performance on real data\")\n",
    "    \n",
    "    if training_results:\n",
    "        print(f\"\\n💡 Optimization Tips:\")\n",
    "        if validation_results and hasattr(validation_results, 'box'):\n",
    "            if validation_results.box.map50 < 0.7:\n",
    "                print(f\"   - Try training for more epochs\")\n",
    "                print(f\"   - Increase model size (yolov8s or yolov8m)\")\n",
    "                print(f\"   - Add more training data\")\n",
    "                print(f\"   - Adjust data augmentation\")\n",
    "            else:\n",
    "                print(f\"   - Model performance is good!\")\n",
    "                print(f\"   - Consider model compression for deployment\")\n",
    "                print(f\"   - Test on edge devices (Raspberry Pi)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Generate summary\n",
    "generate_training_summary(config, training_results, validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usage-examples"
   },
   "outputs": [],
   "source": [
    "# Usage examples for trained model\n",
    "def show_usage_examples(config):\n",
    "    print(\"💻 USAGE EXAMPLES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model_path = f\"{config.project_name}/{config.experiment_name}/weights/best.pt\"\n",
    "    \n",
    "    print(\"\\n🐍 Python Usage:\")\n",
    "    print(\"```python\")\n",
    "    print(\"from ultralytics import YOLO\")\n",
    "    print(\"\")\n",
    "    print(f\"# Load trained model\")\n",
    "    print(f\"model = YOLO('{model_path}')\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference on single image\")\n",
    "    print(\"results = model('path/to/image.jpg')\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference on multiple images\")\n",
    "    print(\"results = model(['img1.jpg', 'img2.jpg'])\")\n",
    "    print(\"\")\n",
    "    print(\"# Save results with annotations\")\n",
    "    print(\"for r in results:\")\n",
    "    print(\"    r.save(filename='result.jpg')\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n🖥️ Command Line Usage:\")\n",
    "    print(\"```bash\")\n",
    "    print(f\"# Single image prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=image.jpg\")\n",
    "    print(\"\")\n",
    "    print(f\"# Batch prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=images_folder/\")\n",
    "    print(\"\")\n",
    "    print(f\"# Video prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=video.mp4\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n🌐 Integration with detect_insect.py:\")\n",
    "    print(\"```bash\")\n",
    "    print(f\"# Use trained model with detection script\")\n",
    "    print(f\"python detect_insect.py \\\\\")\n",
    "    print(f\"    --input input_images/ \\\\\")\n",
    "    print(f\"    --output output_images/ \\\\\")\n",
    "    print(f\"    --model {model_path}\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n📱 Export for Edge Deployment:\")\n",
    "    print(\"```python\")\n",
    "    print(\"# Export to ONNX for cross-platform deployment\")\n",
    "    print(f\"model = YOLO('{model_path}')\")\n",
    "    print(\"model.export(format='onnx')\")\n",
    "    print(\"\")\n",
    "    print(\"# Export to TensorRT for NVIDIA GPUs\")\n",
    "    print(\"model.export(format='engine')\")\n",
    "    print(\"```\")\n",
    "\n",
    "# Show usage examples\n",
    "if training_results:\n",
    "    show_usage_examples(config)\n",
    "else:\n",
    "    print(\"⚠️ No usage examples available - training was not completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## 🎉 Training Complete!\n",
    "\n",
    "**Congratulations!** You have successfully completed the YOLOv8 training pipeline for insect detection.\n",
    "\n",
    "### 📋 What You've Accomplished:\n",
    "- ✅ Set up GPU-accelerated training environment\n",
    "- ✅ Prepared and validated beetle detection dataset\n",
    "- ✅ Trained custom YOLOv8 model\n",
    "- ✅ Evaluated model performance\n",
    "- ✅ Exported model for deployment\n",
    "- ✅ Saved results to Google Drive\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "1. **Download your trained model** (`best.pt`) for local use\n",
    "2. **Test the model** on new beetle images\n",
    "3. **Deploy to production** using the provided usage examples\n",
    "4. **Monitor performance** and retrain as needed\n",
    "\n",
    "### 📚 Resources:\n",
    "- [YOLOv8 Documentation](https://docs.ultralytics.com/)\n",
    "- [Model Deployment Guide](https://docs.ultralytics.com/modes/export/)\n",
    "- [Performance Optimization](https://docs.ultralytics.com/guides/model-optimization/)\n",
    "\n",
    "---\n",
    "\n",
    "*🐛 Happy beetle detecting! 🐛*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}